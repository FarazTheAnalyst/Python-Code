{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\thars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\thars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\thars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\thars\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Article  \\\n",
      "0  Data analysis is the process of inspecting and...   \n",
      "1  The performance of a machine learning algorith...   \n",
      "2  You must have seen the news divided into categ...   \n",
      "3  When there are only two classes in a classific...   \n",
      "4  The Multinomial Naive Bayes is one of the vari...   \n",
      "\n",
      "                                               Title  \n",
      "0                  Best Books to Learn Data Analysis  \n",
      "1         Assumptions of Machine Learning Algorithms  \n",
      "2          News Classification with Machine Learning  \n",
      "3  Multiclass Classification Algorithms in Machin...  \n",
      "4        Multinomial Naive Bayes in Machine Learning  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "data = pd.read_csv(\"articles.csv\", encoding = 'latin1')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we are working on a Natural Language Processing problem, we need to clean the textual \n",
    "# content by removing punctuation and stopwords. Hereâ€™s how we can clean the textual data:\n",
    "def preprocess_text(text):\n",
    "    #convert text to lower\n",
    "    text = text.lower()\n",
    "    #remove punctution\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    #tokenize text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    #remove punctuation\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    #lemmatize tokens\n",
    "    lemma = WordNetLemmatizer()\n",
    "    tokens = [lemma.lemmatize(word) for word in tokens]\n",
    "    #join tokens to form preprocessed text\n",
    "    preprocessed_text = \" \".join(tokens)\n",
    "    return preprocessed_text\n",
    "    \n",
    "data[\"Article\"] = data[\"Article\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to convert the textual data into a numerical representation. We can use text vectorization here:\n",
    "vectorizer = TfidfVectorizer()\n",
    "x = vectorizer.fit_transform(data[\"Article\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Article  \\\n",
      "0  data analysis process inspecting exploring dat...   \n",
      "1  performance machine learning algorithm particu...   \n",
      "2  must seen news divided category go news websit...   \n",
      "3  two class classification problem problem binar...   \n",
      "4  multinomial naive bayes one variant naive baye...   \n",
      "\n",
      "                                               Title  topic_labels  \n",
      "0                  Best Books to Learn Data Analysis             2  \n",
      "1         Assumptions of Machine Learning Algorithms             3  \n",
      "2          News Classification with Machine Learning             1  \n",
      "3  Multiclass Classification Algorithms in Machin...             3  \n",
      "4        Multinomial Naive Bayes in Machine Learning             1  \n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda.fit(x)\n",
    "\n",
    "topic_modelling = lda.transform(x)\n",
    "\n",
    "topic_labels = np.argmax(topic_modelling, axis=1)\n",
    "data[\"topic_labels\"] = topic_labels\n",
    "\n",
    "#now here's the final data with topic label's\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
